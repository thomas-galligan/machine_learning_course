{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "neural_networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpgall1996/machine_learning_course/blob/master/neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "B9_SeEZZBhHM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Chapter 3: Neural Networks**\n",
        "\n",
        "(Credit to William Hartemink for suggesting this much nicer notebook environment)\n",
        "\n",
        "---\n",
        "We now introduce Artificial Neural Networks, one of the most frequently used and powerful machine learning techniques available. The field of Neural Networks (also called Deep Learning) is rich and deep, and we will only see the tip of the iceberg in this course. You know the score by now, so let's jump into coding. You can either run the cells in the notebook, or you can type the code into your own command line if you have Keras and TensorFlow installed.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "3S4O8SAuCPIu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Sequential"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hzTYGX3HDKTW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We have imported the standard Feedworward (sequential) Neural Network. Now let's load in the MNIST data from last time. "
      ]
    },
    {
      "metadata": {
        "id": "XyUXN_mPDQRo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M9QYDg8aDdWF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the data. "
      ]
    },
    {
      "metadata": {
        "id": "242s0A2xDcM7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.imshow(x_train[239,:,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7RY7CIU7Dj_Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We need to change our data shape so that it's a normal (2D) array for inputting into the neural network."
      ]
    },
    {
      "metadata": {
        "id": "oE1ZAUkxDgiW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.reshape(60000,28**2)\n",
        "x_test = x_test.reshape(10000,28**2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1h4kxn9nEVMX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we're ready to build our Neural Network. "
      ]
    },
    {
      "metadata": {
        "id": "KzUy2kqLFzgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "from keras.layers import Dense\n",
        "model.add(Dense(units=100, activation = 'relu', input_dim=28**2))\n",
        "model.add(Dense(units=100,activation = 'relu'))\n",
        "model.add(Dense(units=100,activation = 'relu'))\n",
        "model.add(Dense(units=100,activation = 'relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZ_U9yBtHtUZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since this is a classification problem, our output vector will be 10 dimensional. This isn't the way that our target data arrives, so we need to convert it. "
      ]
    },
    {
      "metadata": {
        "id": "dn6BPk7wI2BB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(y_train[0])\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train,num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test,num_classes=10)\n",
        "\n",
        "print(y_train[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pk2jwY1cKwh9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can now define a loss function for our Neural Network to optimise on. The 'categorial cross-entropy':"
      ]
    },
    {
      "metadata": {
        "id": "ZbCU7rAFK27Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmu2OfCPLWHj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we're ready to train:"
      ]
    },
    {
      "metadata": {
        "id": "Nhj2LYM8LYYq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train, epochs=50, batch_size = 1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bsU9nxitL7vW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Our neural network is trained! Let's have a look at what we've done:"
      ]
    },
    {
      "metadata": {
        "id": "-qD-1Xfreo-M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QcsDBkfue1cU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can evaluate the model's performance:"
      ]
    },
    {
      "metadata": {
        "id": "OM7hSRSaN2KX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model.evaluate(x_test,y_test))\n",
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mwBuWo-wctkE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can also design our own metric of performance, which gives us a lot of flexibility\n"
      ]
    },
    {
      "metadata": {
        "id": "JqSxOH6mMFu-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "counter=0\n",
        "for i in range(10000):\n",
        "  if np.argmax(y_pred[i,:]) != np.argmax(y_test[i,:]):\n",
        "    counter += 1\n",
        "    \n",
        "print(counter/10000)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-DKImbEPHey",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model only gets the answer wrong around 4% of the time. Let's have a quick visual look at our Neural Network's results:"
      ]
    },
    {
      "metadata": {
        "id": "O2iAjNNFPczI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "N=5\n",
        "start_val = 403# pick an element for the code to plot the following 25 values\n",
        "fig, axes = plt.subplots(N,N)\n",
        "items = ['Top','Trousers','Jumper','Dress','Coat','Sandal','Shirt','Trainer',\n",
        "         'Bag','Ankle Boot']\n",
        "for row in range(N):\n",
        "  for col in range(N):\n",
        "    pred = np.argmax(y_pred[start_val+row+N*col,:])\n",
        "    axes[row,col].imshow(x_test[start_val+row+N*col,:].reshape((28,28)))\n",
        "    axes[row,col].set_title(str(items[pred]))\n",
        "    axes[row,col].set_xticks([])\n",
        "    axes[row,col].set_yticks([])\n",
        "    \n",
        "plt.subplots_adjust(hspace=1.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zjrbqu9cnxFY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can also perform cross validation to tune our Neural Network. This is optional (takes a while to run). \n",
        "\n",
        "*(Inspiration from https://www.kaggle.com/stefanie04736/simple-keras-model-with-k-fold-cross-validation)*"
      ]
    },
    {
      "metadata": {
        "id": "7P0T31q2nwbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train = x_train.reshape(60000,28**2)\n",
        "x_test = x_test.reshape(10000,28**2)\n",
        "\n",
        "def get_model(layers, phis):\n",
        "  # takes in a list of integers for layers, and a list of strings for the\n",
        "  # activation functions. \n",
        "  if len(layers) != len(phis):\n",
        "    print('You need to have lists of equal sizes as arguments for model object')\n",
        "  else:\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=layers[0], activation = phis[0], input_dim=28**2))\n",
        "    for i in range(1,len(layers)):\n",
        "      model.add(Dense(units=layers[i], activation = phis[i]))\n",
        "    \n",
        "    model.add(Dense(units=10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "  return model\n",
        "\n",
        "def accuracy(model,x_test,y_test):\n",
        "  #simple accuracy metric for the NN\n",
        "  y_pred = model.predict(x_test)\n",
        "  counter=0\n",
        "  for i in range(len(x_test)):\n",
        "    if np.argmax(y_pred[i,:]) != np.argmax(y_test[i,:]):\n",
        "      counter += 1\n",
        "    \n",
        "  return counter/len(y_test)\n",
        "  \n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "n_folds = 10\n",
        "skf = StratifiedKFold(n_splits=n_folds, random_state=42,shuffle=False)\n",
        "\n",
        "layer_options = [[100,100,100],[50,100,50],[100,200,100,100,50],[50,50,50,50,50,50]] # only the inner layers\n",
        "phi_options = [['relu','relu','relu'],['relu','relu','relu'],['relu','relu','relu','relu','relu'],\n",
        "               ['relu','relu','relu','relu','relu','relu',]]\n",
        "\n",
        "k_scores = []\n",
        "#loop through possible models\n",
        "for k in range(np.shape(layer_options)[0]):\n",
        "  cv_scores = []\n",
        "  \n",
        "  #cross validate this model\n",
        "  for train_ind, test_ind in skf.split(x_train,y_train):\n",
        "    x_train_cv, x_test_cv = x_train[train_ind], x_train[test_ind]\n",
        "    y_train_cv, y_test_cv = y_train[train_ind], y_train[test_ind]\n",
        "    \n",
        "    #convert format of label data for model fitting\n",
        "    y_train_cv_cat = keras.utils.to_categorical(y_train_cv,num_classes=10)\n",
        "    y_test_cv_cat = keras.utils.to_categorical(y_test_cv,num_classes=10)\n",
        "    \n",
        "    model = get_model(layer_options[k],phi_options[k])\n",
        "    model.fit(x_train_cv,y_train_cv_cat,epochs=100, batch_size = 1000)\n",
        "    cv_scores.append(accuracy(model,x_test_cv,y_test_cv_cat))\n",
        "  k_scores.append(np.mean(cv_scores))                \n",
        "print('k_scores are (lower is better):\\n', k_scores)\n",
        "print('Best model is model ',str(np.argmin(k_scores)+1),'with hidden layers:\\n',\n",
        "      layer_options[np.argmin(k_scores)], '\\n and activations:\\n', phi_options[np.argmin(k_scores)])\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}